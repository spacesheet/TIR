[%hardbreaks]
LLM (Large Language Model): 자연어를 이해하고 텍스트를 생성하는 언어 추론 ex)GPT-4, Claude, LLaMA
LLM Agent: LLM을 활용해 목표를 세우고 도구를 사용하며 작업을 수행하는 실행 주체 ex)Claude Code, Open-Code, Cursor
MCP (Model Context Protocol): LLM/Agent가 외부 도구와 데이터를 표준화된 방식으로 연결하기 위한 통신 규약
MCP Server: MCP 규격을 구현해 실제 기능과 데이터를 제공하는 외부 서비스

파운데이션 모델 (Foundation Model):
다양한 작업에 적용할 수 있도록 대규모 데이터로 학습된 범용 AI 모델

대규모 언어 모델 (LLM, Large Language Model):
방대한 텍스트 데이터로 학습되어 언어를 이해하고 생성하는 대형 신경망 모델

지도 학습 (Supervised Learning):
정답(레이블)이 있는 데이터로 모델을 학습시키는 방법

자기 지도 학습 (Self-Supervised Learning):
레이블 없이 데이터 자체의 구조를 이용해 학습하는 방법 (예: 다음 단어 예측)

딥러닝 (Deep Learning):
여러 층의 신경망을 사용하여 복잡한 패턴을 학습하는 기계학습 기법

컨텍스트 (Context):
모델이 응답을 생성할 때 참고하는 이전 대화나 입력 정보

프롬프트 (Prompt):
모델에게 주어지는 입력 텍스트나 지시사항

자연어 처리 (NLP, Natural Language Processing):
컴퓨터가 인간의 언어를 이해하고 처리하는 기술 분야

자연어 지도 (Natural Language Instruction):
사람의 일반 언어로 모델에게 작업을 지시하는 방법

임베딩 모델 (Embedding Model):
텍스트를 고정 크기의 숫자 벡터로 변환하는 모델

인코딩 (Encoding):
텍스트나 데이터를 모델이 처리할 수 있는 숫자 형태로 변환하는 과정

디코딩 (Decoding):
모델의 숫자 출력을 사람이 이해할 수 있는 텍스트로 변환하는 과정

임베딩 (Embedding):
단어나 문장을 의미를 담은 고차원 벡터로 표현한 것

토큰화 (Tokenization):
텍스트를 모델이 처리하는 작은 단위(토큰)로 나누는 과정

파인튜닝 (Fine-tuning):
사전 학습된 모델을 특정 작업이나 도메인에 맞게 추가 학습시키는 것

검색 증강 생성 (RAG, Retrieval-Augmented Generation):
외부 문서를 검색해서 그 정보를 바탕으로 답변을 생성하는 기법

에이전트 (Agent):
목표를 달성하기 위해 도구를 사용하고 행동을 결정하는 AI 시스템

모델 가중치 (Model Weights):
신경망의 학습된 파라미터 값들

저자원 언어 (Low-Resource Language):
학습 데이터가 부족한 언어 (예: 소수 언어)

트랜스포머 아키텍처 (Transformer Architecture):
어텐션 메커니즘 기반으로 순차 데이터를 병렬 처리하는 신경망 구조

어텐션 메커니즘 (Attention Mechanism):
입력의 어느 부분이 중요한지 가중치를 계산하여 집중하는 기법

트랜스포머 블록 (Transformer Block):
어텐션 모듈과 피드포워드 신경망으로 구성된 트랜스포머의 기본 반복 단위

어텐션 모듈 (Attention Module):
입력 간의 관계를 계산하는 트랜스포머 블록의 핵심 구성요소

MLP 모듈 (MLP, Multi-Layer Perceptron Module):
여러 층의 완전연결 신경망으로 구성된 피드포워드 네트워크

임베딩 모듈 (Embedding Module):
토큰을 벡터로 변환하는 신경망의 초기 레이어

컴퓨팅-최적 모델 (Compute-Optimal Model):
주어진 연산 자원 대비 최고 성능을 내도록 모델 크기와 데이터 양을 조정한 모델

사전 학습 (Pre-training):
대규모 데이터로 모델의 기본 지식을 학습시키는 초기 단계

사후 학습 (Post-training):
사전 학습 후 특정 능력 향상을 위한 추가 학습 (파인튜닝, RLHF 등)

샘플링 (Sampling):
모델이 예측한 확률 분포에서 다음 토큰을 선택하는 과정

로그프롭 (Logprob, Log Probability):
각 토큰이 선택될 확률의 로그값 (모델의 확신도 측정에 사용)
